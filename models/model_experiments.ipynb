{
 "cells": [
  {
   "cell_type": "code",
   "id": "91042a72-b81b-4b5b-a8eb-b284b8d93f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:42:08.320400Z",
     "start_time": "2025-12-07T10:42:08.309618Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# Cell 1 â€” Imports, paths, MLflow setup\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… Imports OK\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Robust project root detection\n",
    "# ---------------------------------------------------------\n",
    "ROOT = Path().resolve()  # current dir (probably .../models)\n",
    "\n",
    "if not (ROOT / \"data\").exists():\n",
    "    ROOT = ROOT.parent  # go up to project root\n",
    "\n",
    "DATA_RAW = ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "print(\"Project root:\", ROOT)\n",
    "print(\"Raw data folder:\", DATA_RAW)\n",
    "print(\"Processed data folder:\", DATA_PROCESSED)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MLflow tracking: use SAME DB as scripts\n",
    "# ---------------------------------------------------------\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{ROOT / 'mlflow.db'}\")\n",
    "mlflow.set_experiment(\"MovieLens_Recs_Models\")\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"âœ… MLflow configured\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports OK\n",
      "Project root: C:\\Users\\hibaz\\PycharmProjects\\MLOPSmovierecommendation\n",
      "Raw data folder: C:\\Users\\hibaz\\PycharmProjects\\MLOPSmovierecommendation\\data\\raw\n",
      "Processed data folder: C:\\Users\\hibaz\\PycharmProjects\\MLOPSmovierecommendation\\data\\processed\n",
      "MLflow tracking URI: sqlite:///C:\\Users\\hibaz\\PycharmProjects\\MLOPSmovierecommendation\\mlflow.db\n",
      "âœ… MLflow configured\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "cf3ccda2-49f7-4573-a3f1-2397297daf36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:10:18.129999Z",
     "start_time": "2025-12-07T10:10:18.124644Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# Cell 2 â€” Load data & build userâ€“item matrix\n",
    "# =========================================================\n",
    "# Ratings: we only need userId, movieId, rating\n",
    "ratings_raw = pd.read_csv(DATA_RAW / \"ratings.csv\")\n",
    "ratings = ratings_raw[[\"userId\", \"movieId\", \"rating\"]].copy()\n",
    "\n",
    "# Movies: use processed if available (better genres); fallback to raw\n",
    "movies_path_processed = DATA_PROCESSED / \"movies_processed.csv\"\n",
    "if movies_path_processed.exists():\n",
    "    movies = pd.read_csv(movies_path_processed)\n",
    "else:\n",
    "    movies = pd.read_csv(DATA_RAW / \"movies.csv\")\n",
    "\n",
    "print(\"Ratings shape:\", ratings.shape)\n",
    "print(\"Movies shape:\", movies.shape)\n",
    "\n",
    "# ------- Train/Test split on ratings (for RMSE) -------\n",
    "train_ratings, test_ratings = train_test_split(\n",
    "    ratings,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train ratings:\", train_ratings.shape)\n",
    "print(\"Test ratings:\", test_ratings.shape)\n",
    "\n",
    "# ------- Build userâ€“item matrix from TRAIN ONLY -------\n",
    "user_item_matrix = train_ratings.pivot_table(\n",
    "    index=\"userId\",\n",
    "    columns=\"movieId\",\n",
    "    values=\"rating\",\n",
    "    fill_value=0.0\n",
    ")\n",
    "\n",
    "print(\"Train matrix shape:\", user_item_matrix.shape)\n",
    "print(\"âœ… Data & matrix ready\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hibaz\\PycharmProjects\\MLOPSmovierecommendation\\models\n",
      "False\n",
      "['Implementationmodels.ipynb', 'mlruns', 'model_experiments.ipynb', 'svd_embeddings.pkl', 'tfidf_vectorizer.pkl']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "b7cdfc3c-2ee4-4928-b4cf-7f6f1613ca0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:43:27.100718Z",
     "start_time": "2025-12-07T10:43:27.093493Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# Cell 3 â€” Helper metrics for Top-N recommendation\n",
    "# =========================================================\n",
    "def precision_at_k(rec, rel, k=10):\n",
    "    return len(set(rec[:k]) & set(rel)) / float(k) if k > 0 else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k(rec, rel, k=10):\n",
    "    return len(set(rec[:k]) & set(rel)) / float(len(rel)) if rel else 0.0\n",
    "\n",
    "\n",
    "def hit_rate_at_k(rec, rel, k=10):\n",
    "    return 1.0 if len(set(rec[:k]) & set(rel)) > 0 else 0.0\n",
    "\n",
    "\n",
    "def ndcg_at_k(rec, rel, k=10):\n",
    "    dcg = 0.0\n",
    "    for i, m in enumerate(rec[:k]):\n",
    "        if m in rel:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    ideal_len = min(len(rel), k)\n",
    "    if ideal_len == 0:\n",
    "        return 0.0\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_len))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    "def evaluate_recommender(ratings_df, recommend_fn, k=10, max_users=200):\n",
    "    \"\"\"\n",
    "    ratings_df: DataFrame with userId, movieId, rating\n",
    "    recommend_fn: function(user_id, k) -> list of movieIds\n",
    "    \"\"\"\n",
    "    precision, recall, hit, ndcg = [], [], [], []\n",
    "\n",
    "    for user in ratings_df[\"userId\"].unique()[:max_users]:\n",
    "        liked = ratings_df[\n",
    "            (ratings_df[\"userId\"] == user) &\n",
    "            (ratings_df[\"rating\"] >= 4.0)\n",
    "            ][\"movieId\"].tolist()\n",
    "\n",
    "        if len(liked) < 2:\n",
    "            continue\n",
    "\n",
    "        recs = recommend_fn(user, k=k)\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        precision.append(precision_at_k(recs, liked, k))\n",
    "        recall.append(recall_at_k(recs, liked, k))\n",
    "        hit.append(hit_rate_at_k(recs, liked, k))\n",
    "        ndcg.append(ndcg_at_k(recs, liked, k))\n",
    "\n",
    "    if not precision:\n",
    "        return {\n",
    "            \"precision_at_10\": 0.0,\n",
    "            \"recall_at_10\": 0.0,\n",
    "            \"hit_rate_at_10\": 0.0,\n",
    "            \"ndcg_at_10\": 0.0,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"precision_at_10\": float(np.mean(precision)),\n",
    "        \"recall_at_10\": float(np.mean(recall)),\n",
    "        \"hit_rate_at_10\": float(np.mean(hit)),\n",
    "        \"ndcg_at_10\": float(np.mean(ndcg)),\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Metrics helpers ready\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metrics helpers ready\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "3c82c9dc-0cbc-4c18-97a6-c854ecae6424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:43:58.684031Z",
     "start_time": "2025-12-07T10:43:58.462564Z"
    }
   },
   "source": [
    "\n",
    "# =========================================================\n",
    "# Cell 4 â€” Baseline model (global popularity)\n",
    "# =========================================================\n",
    "def train_baseline(train_ratings_df):\n",
    "    \"\"\"\n",
    "    Baseline: predict using mean rating per movie (popularity).\n",
    "    Returns a Series indexed by movieId, sorted descending.\n",
    "    \"\"\"\n",
    "    movie_mean = train_ratings_df.groupby(\"movieId\")[\"rating\"].mean()\n",
    "    movie_mean = movie_mean.sort_values(ascending=False)\n",
    "    return movie_mean\n",
    "\n",
    "\n",
    "def rmse_baseline(train_ratings_df, test_ratings_df):\n",
    "    movie_mean = train_ratings_df.groupby(\"movieId\")[\"rating\"].mean()\n",
    "    global_mean = train_ratings_df[\"rating\"].mean()\n",
    "\n",
    "    def predict(row):\n",
    "        return movie_mean.get(row[\"movieId\"], global_mean)\n",
    "\n",
    "    preds = test_ratings_df.apply(predict, axis=1)\n",
    "    mse = mean_squared_error(test_ratings_df[\"rating\"], preds)\n",
    "    return float(np.sqrt(mse))\n",
    "\n",
    "\n",
    "# ----- Train + evaluate + log in MLflow -----\n",
    "with mlflow.start_run(run_name=\"baseline_popularity\"):\n",
    "    print(\"Training Popularity Baseline...\")\n",
    "\n",
    "    movie_rankings = train_baseline(train_ratings)\n",
    "    rmse_b = rmse_baseline(train_ratings, test_ratings)\n",
    "\n",
    "\n",
    "    def baseline_rec_fn(user_id, k=10):\n",
    "        return list(movie_rankings.head(k).index)\n",
    "\n",
    "\n",
    "    baseline_metrics = evaluate_recommender(ratings, baseline_rec_fn, k=10)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"baseline_popularity\")\n",
    "    mlflow.log_metric(\"rmse\", rmse_b)\n",
    "    for mk, mv in baseline_metrics.items():\n",
    "        mlflow.log_metric(mk, mv)\n",
    "\n",
    "    print(\"Baseline RMSE:\", rmse_b)\n",
    "    print(\"Baseline metrics:\", baseline_metrics)\n",
    "\n",
    "print(\"âœ… Baseline model finished\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Popularity Baseline...\n",
      "Baseline RMSE: 0.9827389937822489\n",
      "Baseline metrics: {'precision_at_10': 0.001, 'recall_at_10': 7.402753496503496e-05, 'hit_rate_at_10': 0.01, 'ndcg_at_10': 0.0011200278075758777}\n",
      "âœ… Baseline model finished\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "736a2543-a46d-4daf-8c8b-30bd50f6fca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:44:57.877372Z",
     "start_time": "2025-12-07T10:44:56.703553Z"
    }
   },
   "source": [
    "\n",
    "# =========================================================\n",
    "# Cell 5 â€” Content-based TF-IDF model\n",
    "# =========================================================\n",
    "def build_tfidf_content_model(movies_df, max_features=5000):\n",
    "    \"\"\"\n",
    "    Content-based model: TF-IDF on title + genres.\n",
    "    Returns (tfidf_vectorizer, tfidf_matrix, cosine_sim, movie_ids)\n",
    "    \"\"\"\n",
    "    df = movies_df.copy()\n",
    "\n",
    "    # Make sure columns exist\n",
    "    if \"genres\" not in df.columns:\n",
    "        df[\"genres\"] = \"\"\n",
    "    if \"title\" not in df.columns:\n",
    "        df[\"title\"] = \"\"\n",
    "\n",
    "    df[\"genres\"] = df[\"genres\"].fillna(\"\")\n",
    "    df[\"title\"] = df[\"title\"].fillna(\"\")\n",
    "    df[\"combined_text\"] = df[\"title\"] + \" \" + df[\"genres\"]\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\", max_features=max_features)\n",
    "    tfidf_matrix = tfidf.fit_transform(df[\"combined_text\"])\n",
    "\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    movie_ids = df[\"movieId\"].values\n",
    "\n",
    "    return tfidf, tfidf_matrix, cosine_sim, movie_ids\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"content_tfidf\"):\n",
    "    print(\"Training TF-IDF content model...\")\n",
    "\n",
    "    tfidf, tfidf_matrix, cosine_sim, cb_movie_ids = build_tfidf_content_model(\n",
    "        movies, max_features=5000\n",
    "    )\n",
    "\n",
    "    # index mapping: movieId -> row index in cosine_sim\n",
    "    movieid_to_index = {m: i for i, m in enumerate(cb_movie_ids)}\n",
    "\n",
    "\n",
    "    def tfidf_rec_fn(user_id, k=10):\n",
    "        user_ratings = ratings[\n",
    "            (ratings[\"userId\"] == user_id) &\n",
    "            (ratings[\"rating\"] >= 4.0)\n",
    "            ]\n",
    "        liked_movies = user_ratings[\"movieId\"].tolist()\n",
    "        if not liked_movies:\n",
    "            return []\n",
    "\n",
    "        anchor = liked_movies[0]\n",
    "        if anchor not in movieid_to_index:\n",
    "            return []\n",
    "\n",
    "        anchor_idx = movieid_to_index[anchor]\n",
    "        sims = cosine_sim[anchor_idx]\n",
    "\n",
    "        # sort all movies by similarity\n",
    "        sorted_idx = np.argsort(sims)[::-1]\n",
    "\n",
    "        # remove movies already rated by user\n",
    "        rated_movies = ratings[ratings[\"userId\"] == user_id][\"movieId\"].unique().tolist()\n",
    "        rated_set = set(rated_movies)\n",
    "\n",
    "        rec_ids = []\n",
    "        for idx in sorted_idx:\n",
    "            movie_id = cb_movie_ids[idx]\n",
    "            if movie_id in rated_set:\n",
    "                continue\n",
    "            rec_ids.append(movie_id)\n",
    "            if len(rec_ids) >= k:\n",
    "                break\n",
    "\n",
    "        return rec_ids\n",
    "\n",
    "\n",
    "    content_metrics = evaluate_recommender(ratings, tfidf_rec_fn, k=10)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"content_tfidf\")\n",
    "    mlflow.log_param(\"tfidf_max_features\", 5000)\n",
    "    for mk, mv in content_metrics.items():\n",
    "        mlflow.log_metric(mk, mv)\n",
    "\n",
    "    print(\"Content-based metrics:\", content_metrics)\n",
    "\n",
    "print(\"âœ… Content-based model finished\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TF-IDF content model...\n",
      "Content-based metrics: {'precision_at_10': 0.0, 'recall_at_10': 0.0, 'hit_rate_at_10': 0.0, 'ndcg_at_10': 0.0}\n",
      "âœ… Content-based model finished\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "c75a5771-d214-43a9-aa40-ba2801747761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:45:28.344107Z",
     "start_time": "2025-12-07T10:45:27.662391Z"
    }
   },
   "source": [
    "\n",
    "# =========================================================\n",
    "# Cell 6 â€” SVD Collaborative Filtering\n",
    "# =========================================================\n",
    "def train_svd_cf(user_item_mat, n_components=50):\n",
    "    \"\"\"\n",
    "    SVD on userâ€“item rating matrix (train).\n",
    "    Returns dict with factors + RMSE on test set.\n",
    "    \"\"\"\n",
    "    # Matrix R (users x movies)\n",
    "    R = user_item_mat.values.astype(np.float32)\n",
    "    user_ids = user_item_mat.index.values\n",
    "    movie_ids = user_item_mat.columns.values\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=RANDOM_STATE)\n",
    "    user_factors = svd.fit_transform(R)\n",
    "    movie_factors = svd.components_.T  # shape: n_movies x n_components\n",
    "\n",
    "    model_dict = {\n",
    "        \"user_ids\": user_ids,\n",
    "        \"movie_ids\": movie_ids,\n",
    "        \"user_factors\": user_factors,\n",
    "        \"movie_factors\": movie_factors,\n",
    "        \"n_components\": n_components,\n",
    "    }\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def svd_rmse(model_dict, train_ratings_df, test_ratings_df):\n",
    "    user_ids = model_dict[\"user_ids\"]\n",
    "    movie_ids = model_dict[\"movie_ids\"]\n",
    "    user_factors = model_dict[\"user_factors\"]\n",
    "    movie_factors = model_dict[\"movie_factors\"]\n",
    "\n",
    "    user_index_map = {u: i for i, u in enumerate(user_ids)}\n",
    "    movie_index_map = {m: i for i, m in enumerate(movie_ids)}\n",
    "\n",
    "    preds = []\n",
    "    actual = []\n",
    "\n",
    "    for row in test_ratings_df.itertuples():\n",
    "        u = row.userId\n",
    "        m = row.movieId\n",
    "        r = row.rating\n",
    "\n",
    "        if (u not in user_index_map) or (m not in movie_index_map):\n",
    "            continue\n",
    "\n",
    "        u_idx = user_index_map[u]\n",
    "        m_idx = movie_index_map[m]\n",
    "\n",
    "        pred = float(np.dot(user_factors[u_idx], movie_factors[m_idx]))\n",
    "        preds.append(pred)\n",
    "        actual.append(r)\n",
    "\n",
    "    if not preds:\n",
    "        return None\n",
    "\n",
    "    mse = mean_squared_error(actual, preds)\n",
    "    return float(np.sqrt(mse))\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"svd_cf\"):\n",
    "    print(\"Training SVD CF model...\")\n",
    "\n",
    "    n_components = 50\n",
    "    model_svd = train_svd_cf(user_item_matrix, n_components=n_components)\n",
    "\n",
    "    # RMSE\n",
    "    rmse_svd = svd_rmse(model_svd, train_ratings, test_ratings)\n",
    "\n",
    "    user_ids_svd = model_svd[\"user_ids\"]\n",
    "    movie_ids_svd = model_svd[\"movie_ids\"]\n",
    "    user_factors_svd = model_svd[\"user_factors\"]\n",
    "    movie_factors_svd = model_svd[\"movie_factors\"]\n",
    "\n",
    "    user_index_map_svd = {u: i for i, u in enumerate(user_ids_svd)}\n",
    "    movie_index_map_svd = {m: i for i, m in enumerate(movie_ids_svd)}\n",
    "\n",
    "\n",
    "    def svd_rec_fn(user_id, k=10):\n",
    "        if user_id not in user_index_map_svd:\n",
    "            return []\n",
    "\n",
    "        u_idx = user_index_map_svd[user_id]\n",
    "        scores = np.dot(user_factors_svd[u_idx], movie_factors_svd.T)\n",
    "\n",
    "        scores_series = pd.Series(scores, index=movie_ids_svd)\n",
    "\n",
    "        if user_id in user_item_matrix.index:\n",
    "            already_rated = user_item_matrix.loc[user_id]\n",
    "            scores_series = scores_series[already_rated == 0]\n",
    "\n",
    "        top_movies = scores_series.sort_values(ascending=False).head(k).index\n",
    "        return list(top_movies)\n",
    "\n",
    "\n",
    "    svd_metrics = evaluate_recommender(ratings, svd_rec_fn, k=10)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"svd_cf\")\n",
    "    mlflow.log_param(\"n_components\", n_components)\n",
    "    if rmse_svd is not None:\n",
    "        mlflow.log_metric(\"rmse\", rmse_svd)\n",
    "    for mk, mv in svd_metrics.items():\n",
    "        mlflow.log_metric(mk, mv)\n",
    "\n",
    "    print(\"SVD RMSE:\", rmse_svd)\n",
    "    print(\"SVD metrics:\", svd_metrics)\n",
    "\n",
    "print(\"âœ… SVD CF model finished\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVD CF model...\n",
      "SVD RMSE: 3.1668501056771423\n",
      "SVD metrics: {'precision_at_10': 0.20200000000000004, 'recall_at_10': 0.043289030557360365, 'hit_rate_at_10': 0.755, 'ndcg_at_10': 0.23131219349474694}\n",
      "âœ… SVD CF model finished\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "9b241b37-7012-4bff-8fa9-486d1d18f19b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T10:45:55.023928Z",
     "start_time": "2025-12-07T10:45:52.522799Z"
    }
   },
   "source": [
    "\n",
    "# =========================================================\n",
    "# Cell 7 â€” NMF Collaborative Filtering (FIXED)\n",
    "# =========================================================\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def train_nmf_cf(user_item_mat, n_components=40, max_iter=200):\n",
    "    \"\"\"\n",
    "    NMF-based CF: factorization of userâ€“item matrix with non-negative factors.\n",
    "    \"\"\"\n",
    "    R = user_item_mat.values.astype(np.float32)\n",
    "    user_ids = user_item_mat.index.values\n",
    "    movie_ids = user_item_mat.columns.values\n",
    "\n",
    "    nmf = NMF(\n",
    "        n_components=n_components,\n",
    "        init=\"random\",\n",
    "        max_iter=max_iter,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    user_factors = nmf.fit_transform(R)\n",
    "    movie_factors = nmf.components_.T  # n_movies x n_components\n",
    "\n",
    "    model_dict = {\n",
    "        \"user_ids\": user_ids,\n",
    "        \"movie_ids\": movie_ids,\n",
    "        \"user_factors\": user_factors,\n",
    "        \"movie_factors\": movie_factors,\n",
    "        \"n_components\": n_components,\n",
    "    }\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def nmf_rmse(model_dict, train_ratings_df, test_ratings_df):\n",
    "    user_ids = model_dict[\"user_ids\"]\n",
    "    movie_ids = model_dict[\"movie_ids\"]\n",
    "    user_factors = model_dict[\"user_factors\"]\n",
    "    movie_factors = model_dict[\"movie_factors\"]\n",
    "\n",
    "    user_index_map = {u: i for i, u in enumerate(user_ids)}\n",
    "    movie_index_map = {m: i for i, m in enumerate(movie_ids)}\n",
    "\n",
    "    preds = []\n",
    "    actual = []\n",
    "\n",
    "    for row in test_ratings_df.itertuples():\n",
    "        u = row.userId\n",
    "        m = row.movieId\n",
    "        r = row.rating\n",
    "\n",
    "        if (u not in user_index_map) or (m not in movie_index_map):\n",
    "            continue\n",
    "\n",
    "        u_idx = user_index_map[u]\n",
    "        m_idx = movie_index_map[m]\n",
    "\n",
    "        pred = float(np.dot(user_factors[u_idx], movie_factors[m_idx]))\n",
    "        preds.append(pred)\n",
    "        actual.append(r)\n",
    "\n",
    "    if not preds:\n",
    "        return None\n",
    "\n",
    "    mse = mean_squared_error(actual, preds)\n",
    "    return float(np.sqrt(mse))\n",
    "\n",
    "\n",
    "# ---------- RUN + LOG TO MLFLOW ----------\n",
    "with mlflow.start_run(run_name=\"nmf_cf\"):\n",
    "    print(\"Training NMF CF model...\")\n",
    "\n",
    "    n_components_nmf = 40\n",
    "    model_nmf = train_nmf_cf(user_item_matrix, n_components=n_components_nmf)\n",
    "\n",
    "    rmse_nmf = nmf_rmse(model_nmf, train_ratings, test_ratings)\n",
    "\n",
    "    user_ids_nmf = model_nmf[\"user_ids\"]\n",
    "    movie_ids_nmf = model_nmf[\"movie_ids\"]\n",
    "    user_factors_nmf = model_nmf[\"user_factors\"]\n",
    "    movie_factors_nmf = model_nmf[\"movie_factors\"]\n",
    "\n",
    "    user_index_map_nmf = {u: i for i, u in enumerate(user_ids_nmf)}\n",
    "\n",
    "    def nmf_rec_fn(user_id, k=10):\n",
    "        if user_id not in user_index_map_nmf:\n",
    "            return []\n",
    "\n",
    "        u_idx = user_index_map_nmf[user_id]\n",
    "        scores = np.dot(user_factors_nmf[u_idx], movie_factors_nmf.T)\n",
    "        scores_series = pd.Series(scores, index=movie_ids_nmf)\n",
    "\n",
    "        if user_id in user_item_matrix.index:\n",
    "            already_rated = user_item_matrix.loc[user_id]\n",
    "            scores_series = scores_series[already_rated == 0]\n",
    "\n",
    "        top_movies = scores_series.sort_values(ascending=False).head(k).index\n",
    "        return list(top_movies)\n",
    "\n",
    "    nmf_metrics = evaluate_recommender(ratings, nmf_rec_fn, k=10)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"nmf_cf\")\n",
    "    mlflow.log_param(\"n_components\", n_components_nmf)\n",
    "\n",
    "    if rmse_nmf is not None:\n",
    "        mlflow.log_metric(\"rmse\", rmse_nmf)\n",
    "\n",
    "    for mk, mv in nmf_metrics.items():\n",
    "        mlflow.log_metric(mk, mv)\n",
    "\n",
    "    print(\"NMF RMSE:\", rmse_nmf)\n",
    "    print(\"NMF metrics:\", nmf_metrics)\n",
    "\n",
    "print(\"âœ… NMF CF model finished\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NMF CF model...\n",
      "NMF RMSE: 3.1282046075529926\n",
      "NMF metrics: {'precision_at_10': 0.1865, 'recall_at_10': 0.04039343523428452, 'hit_rate_at_10': 0.715, 'ndcg_at_10': 0.21350527968302185}\n",
      "âœ… NMF CF model finished\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "4a06b068-0fe5-49b1-9a6d-6f8c43355afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T11:05:30.200291Z",
     "start_time": "2025-12-07T10:46:14.640334Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# Cell 8 â€” Item-based KNN Collaborative Filtering\n",
    "# =========================================================\n",
    "def train_item_knn_cf(user_item_mat, n_neighbors=40):\n",
    "    \"\"\"\n",
    "    Item-based CF using cosine similarity between movie rating vectors.\n",
    "    \"\"\"\n",
    "    # Transpose: movies x users\n",
    "    item_matrix = user_item_mat.T  # shape: n_movies x n_users\n",
    "    movie_ids = item_matrix.index.values\n",
    "\n",
    "    knn_model = NearestNeighbors(\n",
    "        n_neighbors=n_neighbors,\n",
    "        metric=\"cosine\",\n",
    "        algorithm=\"brute\"\n",
    "    )\n",
    "    knn_model.fit(item_matrix.values)\n",
    "\n",
    "    return knn_model, movie_ids\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"item_knn_cf\"):\n",
    "    print(\"Training item-based KNN CF model...\")\n",
    "\n",
    "    n_neighbors_knn = 40\n",
    "    knn_model, knn_movie_ids = train_item_knn_cf(user_item_matrix, n_neighbors=n_neighbors_knn)\n",
    "\n",
    "    movie_index_map_knn = {m: i for i, m in enumerate(knn_movie_ids)}\n",
    "\n",
    "\n",
    "    def item_knn_rec_fn(user_id, k=10):\n",
    "        # movies user already rated (from TRAIN)\n",
    "        if user_id not in user_item_matrix.index:\n",
    "            return []\n",
    "        user_ratings_vec = user_item_matrix.loc[user_id]\n",
    "        rated_movies = user_ratings_vec[user_ratings_vec > 0].index.tolist()\n",
    "        if not rated_movies:\n",
    "            return []\n",
    "\n",
    "        scores_accum = {}\n",
    "\n",
    "        for m in rated_movies:\n",
    "            if m not in movie_index_map_knn:\n",
    "                continue\n",
    "            m_idx = movie_index_map_knn[m]\n",
    "            movie_vec = user_item_matrix.T.values[m_idx].reshape(1, -1)\n",
    "            distances, indices = knn_model.kneighbors(movie_vec, n_neighbors=n_neighbors_knn)\n",
    "\n",
    "            for dist, idx in zip(distances.flatten(), indices.flatten()):\n",
    "                neighbor_movie = knn_movie_ids[idx]\n",
    "                if neighbor_movie in rated_movies:\n",
    "                    continue\n",
    "                sim = 1.0 - dist  # cosine distance â†’ similarity\n",
    "                scores_accum[neighbor_movie] = scores_accum.get(neighbor_movie, 0.0) + sim\n",
    "\n",
    "        if not scores_accum:\n",
    "            return []\n",
    "\n",
    "        scores_series = pd.Series(scores_accum)\n",
    "        top_movies = scores_series.sort_values(ascending=False).head(k).index\n",
    "        return list(top_movies)\n",
    "\n",
    "\n",
    "    knn_cf_metrics = evaluate_recommender(ratings, item_knn_rec_fn, k=10)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"item_knn_cf\")\n",
    "    mlflow.log_param(\"n_neighbors\", n_neighbors_knn)\n",
    "    for mk, mv in knn_cf_metrics.items():\n",
    "        mlflow.log_metric(mk, mv)\n",
    "\n",
    "    print(\"Item KNN CF metrics:\", knn_cf_metrics)\n",
    "\n",
    "print(\"âœ… Item-based KNN CF finished\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training item-based KNN CF model...\n",
      "Item KNN CF metrics: {'precision_at_10': 0.163, 'recall_at_10': 0.03579994611193533, 'hit_rate_at_10': 0.67, 'ndcg_at_10': 0.18358496430193874}\n",
      "âœ… Item-based KNN CF finished\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "9d118445-ca24-4d81-8c74-88bc66033f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T11:05:39.521786Z",
     "start_time": "2025-12-07T11:05:38.807684Z"
    }
   },
   "source": [
    "# =========================================================\n",
    "# Cell 9 â€” Simple hybrid: SVD + TF-IDF fusion\n",
    "# =========================================================\n",
    "with mlflow.start_run(run_name=\"hybrid_svd_tfidf\"):\n",
    "    print(\"Training Hybrid model (SVD + TF-IDF)...\")\n",
    "\n",
    "\n",
    "    # We reuse SVD and TF-IDF artifacts from above cells:\n",
    "    #   - svd_rec_fn: rating-based recs\n",
    "    #   - tfidf_rec_fn: similarity-based recs\n",
    "    # For a hybrid, we combine scores.\n",
    "\n",
    "    # Precompute for efficiency:\n",
    "    #  - We'll build score dictionaries for each user on the fly.\n",
    "    #    To keep it simple, we combine rankings (not continuous scores).\n",
    "\n",
    "    def hybrid_rec_fn(user_id, k=10):\n",
    "        rec_svd = svd_rec_fn(user_id, k=50) or []\n",
    "        rec_cb = tfidf_rec_fn(user_id, k=50) or []\n",
    "\n",
    "        scores = {}\n",
    "\n",
    "        # Higher weight for SVD (CF is usually stronger)\n",
    "        for rank, m in enumerate(rec_svd):\n",
    "            scores[m] = scores.get(m, 0.0) + (50 - rank)\n",
    "\n",
    "        for rank, m in enumerate(rec_cb):\n",
    "            scores[m] = scores.get(m, 0.0) + 0.5 * (50 - rank)\n",
    "\n",
    "        if not scores:\n",
    "            return []\n",
    "\n",
    "        scores_series = pd.Series(scores)\n",
    "        top_movies = scores_series.sort_values(ascending=False).head(k).index\n",
    "        return list(top_movies)\n",
    "\n",
    "\n",
    "    hybrid_metrics = evaluate_recommender(ratings, hybrid_rec_fn, k=10)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"hybrid_svd_tfidf\")\n",
    "    for mk, mv in hybrid_metrics.items():\n",
    "        mlflow.log_metric(mk, mv)\n",
    "\n",
    "    print(\"Hybrid metrics:\", hybrid_metrics)\n",
    "\n",
    "print(\"âœ… Hybrid model finished\")\n",
    "print(\"ðŸŽ‰ All notebook experiments completed. Open MLflow UI from project root with:  mlflow ui\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hybrid model (SVD + TF-IDF)...\n",
      "Hybrid metrics: {'precision_at_10': 0.196, 'recall_at_10': 0.04146593289036713, 'hit_rate_at_10': 0.755, 'ndcg_at_10': 0.21651720340362204}\n",
      "âœ… Hybrid model finished\n",
      "ðŸŽ‰ All notebook experiments completed. Open MLflow UI from project root with:  mlflow ui\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "93bd85f0d1a62aa0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
